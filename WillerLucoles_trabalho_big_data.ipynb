{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillerLucoles/Spark_Bigdata/blob/main/WillerLucoles_trabalho_big_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpEDihRflc3l"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iikBuie2lc3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26bba6e-e02f-4500-d1a6-85ded89caf80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-03 22:35:53--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‘imdb-reviews-pt-br.zip’\n",
            "\n",
            "imdb-reviews-pt-br. 100%[===================>]  47.25M   218MB/s    in 0.2s    \n",
            "\n",
            "2024-10-03 22:35:53 (218 MB/s) - ‘imdb-reviews-pt-br.zip’ saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "  inflating: imdb-reviews-pt-br.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haMBxlFelc3r"
      },
      "source": [
        "## Instalação manual das dependências para uso do pyspark no Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ysr5kTBTlc3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95e83b5-d03b-4602-b196-9ca2c33cfb38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=a957e76161bbed485f2a35759fabbc0184c1e438b6a943ca1fb00292615afedc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TNsVbpPlc3t"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oCMKKbsilc3u"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exj9BrF3lc3w"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o método read.csv do spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uZIDC5T7lc3x"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M_e5HeLlc3y"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRugGhRRlc3z"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e o \"id\" como valor do tipo inteiro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KwMBi8pilc3z"
      },
      "outputs": [],
      "source": [
        "def map1(row):\n",
        "    if row['sentiment'] == 'neg':\n",
        "        return (row['sentiment'], int(row['id']))\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZSWxBSXlc30"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar os IDs por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o85uWxV2lc30"
      },
      "outputs": [],
      "source": [
        "def reduceByKey1(x, y):\n",
        "    return x + y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndjZ12uPlc31"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sfGrThi3lc31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14a6b75-7ab0-44ca-ef7c-ef9794e487d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Willer Lucas - RU: 1351633\n",
            "Resultado da soma dos IDs para resenhas negativas: [('neg', 459568555)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rdd = imdb_df.rdd\n",
        "mapped_rdd = rdd.map(map1).filter(lambda x: x is not None)\n",
        "result = mapped_rdd.reduceByKey(reduceByKey1).collect()\n",
        "\n",
        "print(\"Willer Lucas - RU: 1351633\")\n",
        "print(f\"Resultado da soma dos IDs para resenhas negativas: {result}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYQsWZetkQxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQIUpcuylc31"
      },
      "source": [
        "# Questão 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHe8UNk7lc31"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e uma tupla com a soma das palavras de cada texto como valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MJ2oJKH6lc32"
      },
      "outputs": [],
      "source": [
        "def map2(row):\n",
        "    if row['sentiment'] == 'neg':\n",
        "        num_words_pt = len(row['text_pt'].split()) if row['text_pt'] else 0\n",
        "        num_words_en = len(row['text_en'].split()) if row['text_en'] else 0\n",
        "        return (row['sentiment'], (num_words_pt, num_words_en))\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwEVaoBOlc32"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar o numero de palavras de cada texto português e inglês por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xyKkltmNlc33"
      },
      "outputs": [],
      "source": [
        "def reduceByKey2(x, y):\n",
        "    return (x[0] + y[0], x[1] + y[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzCUFqKKlc33"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado\n",
        "\n",
        "1. Aplicar o map/reduce no seu dataframe spark e realizar o collect() ao final\n",
        "2. Selecionar os dados referentes aos textos negativos para realizar a subtração.\n",
        "3. Realizar a subtração das contagens de palavras dos textos negativos para obter o resultado final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zboLSbMolc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a0d1aa-1348-42de-c802-7378fa17deb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de palavras em português: 5455273\n",
            "Total de palavras em inglês: 5400324\n",
            "Diferença (português - inglês): 54949\n",
            "Willer Lucas - RU: 1351633\n"
          ]
        }
      ],
      "source": [
        "rdd = imdb_df.rdd\n",
        "mapped_rdd = rdd.map(map2).filter(lambda x: x is not None)\n",
        "result = mapped_rdd.reduceByKey(reduceByKey2).collect()\n",
        "\n",
        "for sentiment, (total_words_pt, total_words_en) in result:\n",
        "    print(f\"Total de palavras em português: {total_words_pt}\")\n",
        "    print(f\"Total de palavras em inglês: {total_words_en}\")\n",
        "    print(f\"Diferença (português - inglês): {total_words_pt - total_words_en}\")\n",
        "print(\"Willer Lucas - RU: 1351633\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}